{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cd2fea0",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "    <div style=\"float: left; width: 50%;\">\n",
    "       <img src=\"https://www.uoc.edu/portal/system/modules/edu.uoc.presentations/resources/img/branding/logo-uoc-default.png\", align=\"left\">\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "    <p style=\"margin: 0; text-align:right;\">22.503 · Programación para la ciencia de datos</p>\n",
    "    <p style=\"margin: 0; text-align:right;\">Grado en Ciencia de Datos Aplicada</p>\n",
    "    <p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudios de Informática, Multimedia y Telecomunicaciones</p>\n",
    "</div>\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"width:100%;\"> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b140c829",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Programación para la ciencia de datos - PAC2\n",
    "============================\n",
    "\n",
    "En este Notebook encontraréis un conjunto de ejercicios que conforman la segunda actividad de evaluación continua (PAC) de la asignatura.\n",
    "\n",
    "Para cada ejercicio, tened en cuenta que:  \n",
    "\n",
    "* **Es necesario incluir comentarios** de vuestro código, que expliquen cómo ha implementado la solución del problema planteado.  \n",
    "* **Es imprescindible** citar las referencias consultadas para realizar la actividad. Se valorará que el código proporcionado solucione el problema propuesto y también la calidad del código (comentarios, legibilidad, claridad, uso de las estructuras de datos adecuadas, buena nomenclatura de las variables y funciones, seguimiento del PEP8, etc. ).\n",
    "\n",
    "Vereis que cada una de las actividades tiene asociada una puntuación, que indica el peso que tiene la actividad sobre la nota de la PAC. Adicionalmente, existe una puntuación asociada a aspectos globales de la PAC (*docstring*, modularidad y estilo), que se evaluarán sobre la totalidad del código entregado.\n",
    "\n",
    "Además, todas las actividades tienen una etiqueta, que indica los recursos necesarios para llevarla a cabo. Hay tres posibles etiquetas:\n",
    "* <span style=\"font-family: Courier New; background-color: #82b74b; color: #000000; padding: 3px; \">SM</span>   **Sólo materiales**: las herramientas necesarias para realizar la actividad se pueden encontrar en los materiales de la asignatura (consideraremos también los materiales de la asignatura Fundamentos de Programación, así como las lecturas obligatorias de material externo que se indican en los notebooks).  \n",
    "* <span style=\"font-family: Courier New; background-color: #ffcc5c; color: #000000; padding: 3px; \">EG</span>**Consulta externa guiada**: la actividad puede requerir hacer uso de herramientas que no se encuentran en los materiales de la asignatura, pero el enunciado contiene indicaciones de dónde o cómo encontrar la información adicional necesaria para resolver la actividad.  \n",
    "* <span style=\"font-family: Courier New; background-color: #f2ae72; color: #000000; padding: 3px; \">EI</span>**Consulta externa independiente**: la actividad puede requerir hacer uso de herramientas que no se encuentran en los materiales de la asignatura, y el enunciado puede no incluir la descripción de dónde o cómo encontrar esta información adicional. Será necesario que el estudiante busque esta información utilizando los recursos que se han explicado en la asignatura.\n",
    "\n",
    "Es importante notar que estas etiquetas no indican el nivel de dificultad del ejercicio, sino únicamente la necesidad de consulta de documentación externa para su resolución. Además, recuerde que las**etiquetas son informativas**, pero puede consultar referencias externas siempre que lo desee (aunque no se indique explícitamente) o puede que pueda realizar una actividad sin consultar ningún tipo de documentación. Por ejemplo, para resolver una actividad que sólo requiera los materiales de la asignatura, puede consultar referencias externas si se desea, ya sea tanto para ayudar en la resolución como para ampliar conocimientos!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e15fdf",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Yo, *Álvaro Loarte Rodríguez*, confirmo que he elaborado de manera individual todas las actividades resueltas en esta PEC y que he incluido las citas en todas las fuentes externas que he utilizado para resolver las actividades.\n",
    "\n",
    "## Criterios de corrección\n",
    "\n",
    "Esta PEC se valorará siguiendo los siguientes criterios:\n",
    "\n",
    "* **Funcionalidad** (9 puntos): Se valorará que el código implemente las funcionalidades correspondientes.\n",
    "    * Ejercicio 1 (1 punto)\n",
    "    * Ejercicio 2 (1.5 puntos)\n",
    "    * Ejercicio 3 (2.5 puntos)\n",
    "    * Ejercicio 4 (1 punto)\n",
    "    * Ejercicio 5 (3 puntos)\n",
    "\n",
    "* **Documentación** (0.25f puntos):  Todas las funciones de los ejercicios de esta PEC tendrán que estar debidamente documentadas utilizando docstrings (en el formato que prefiráis). \n",
    "* **Modularidad** (0.5f puntos): Se valorará la modularidad del código (tanto la organización del código en módulos como la creación de funciones). \n",
    "* **Estilo** (0.25f puntos): El código tiene que seguir la guía de estilo de Python (PEP8), exceptuando los casos donde hacerlo complique la legibilidad del código.\n",
    "\n",
    "Donde f es la fracción de la PEC realizada. Es decir, la nota de estos aspectos transversales será proporcional a la parte de la PEC realizada.Así, los aspectos transversales tendrán una puntuación máxima de 1 punto si se entregan todos los ejercicios de la PEC. De lo contrario, la nota de aspectos transversales se multiplicará por la fracción entregada de la PEC . Por ejemplo, si los aspectos transversales están puntuados con un 1 y sólo se ha hecho media PEC, la nota de los aspectos transversales será 1∗0.5=0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55c9db80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T14:46:38.315570Z",
     "start_time": "2024-04-27T14:46:38.310501Z"
    }
   },
   "outputs": [],
   "source": [
    "#%load_ext pycodestyle_magic\n",
    "#%pycodestyle_on\n",
    "\n",
    "# Dejo desactivado el codestyle porque me ha dado muchos problemas. El pycodestyle da un crash (ya me pasó en la PEC1) y no\n",
    "# ejecuta la comprobación del código.\n",
    "# El error que me da es: ValueError: Function <bound method VarWatcher.auto_run_pycodestyle of <pycodestyle_magic.VarWatcher object at 0x74cdecd0fb80>> is not registered as a post_run_cell callback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f335cee8",
   "metadata": {},
   "source": [
    "# Ejercicio 1\n",
    "\n",
    "Queremos crear una función que compruebe si un año es un año bisiesto o no.\n",
    "\n",
    "La función recibirá dos parámetros:\n",
    "- el año que queremos comprobar,\n",
    "- un parámetro **opcional** que nos indique si queremos que la función muestre por pantalla la razón por la cual el año no se considera un año bisiesto (en el caso que el año sea bisiesto, la función no deberá mostrar ningún mensaje de todas formas).\n",
    "\n",
    "La función devolverá un dato de tipo booleano (True / False)*.\n",
    "\n",
    "Según el calendario Gregoriano, un año se considera año bisiesto si cumple las siguientes condiciones:\n",
    "- Si 4 es un divisor del año, es un año bisiesto, excepto\n",
    " - Si 100 también es un divisor del año, en cuyo caso el año **NO** se considera bisiesto, excepto\n",
    "   - Si 400 también es un divisor del año, en cuyo caso el año **SÍ** se considera bisiesto.\n",
    "   \n",
    "Por ejemplo, a continuación podéis ver algunos ejemplos del resultado esperado en función del año.\n",
    "\n",
    "2000 -> True\n",
    "\n",
    "1800 -> False\n",
    "\n",
    "2100 -> False\n",
    "\n",
    "**Nota**. **No podéis utilizar la función `isleap` que hemos visto en la Unidad 1**. Aplicad la función implementada a los años indicados en la celda inferior y comprobad que el resultado es el mismo que el resultado obtenido si utilizamos la función `isleap` de Python.\n",
    "\n",
    "<span style=\"font-family: Courier New; background-color: #82b74b; color: #000000; padding: 3px; \">SM</span> **(1 punto)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "364f96e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T14:46:38.347812Z",
     "start_time": "2024-04-27T14:46:38.339979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The year 1800 is a not leap year because can be divisible by 4 and also by 100 but not by 400.\n",
      "Year: 1800 is leap?: False [C], False[P]\n",
      "Year: 1996 is leap?: True [C], True[P]\n",
      "Year: 2000 is leap?: True [C], True[P]\n",
      "The year 2101 is a not leap year because its not divisible by 4.\n",
      "Year: 2101 is leap?: False [C], False[P]\n",
      "Year: 2400 is leap?: True [C], True[P]\n"
     ]
    }
   ],
   "source": [
    "# Ejercicio 1\n",
    "import calendar\n",
    "\n",
    "def custom_is_leap(year:int,explain:bool = False):\n",
    "    \"\"\"\n",
    "    He creado 4 variables para almacenar las condiciones para comprobar si un número es bisiesto \n",
    "    con el objetivo de más adelante poder imprimir los errores en caso de no ser bisiesto.\n",
    "    La lógica sería la siguiente: (year % 4 == 0 and year % 100 != 0) or year % 400 == 0\n",
    "    \"\"\"\n",
    "    div_four = year % 4 == 0\n",
    "    not_div_one_hundred = year % 100 != 0\n",
    "    div_four_hundred = year % 400 == 0\n",
    "    leap = (div_four and not_div_one_hundred) or div_four_hundred\n",
    "    # Compruebo que la lógica para ser bisiesto se cumpla\n",
    "    if leap or div_four_hundred:\n",
    "        return True\n",
    "    else:\n",
    "        # Si no es bisiesto, compruebo si se indicó la variable para dar un motivo \n",
    "        if explain:\n",
    "            if not div_four:\n",
    "                print(f'The year {year} is a not leap year because its not divisible by 4.')\n",
    "            elif not leap:\n",
    "                print(f'The year {year} is a not leap year because can be divisible by 4 and also by 100 but not by 400.')\n",
    "            else:\n",
    "                print(f'The year {year} is a not leap year for any error.')\n",
    "            \n",
    "        return False\n",
    "\n",
    "\n",
    "years = [1800, 1996, 2000, 2101, 2400]\n",
    "\n",
    "\"\"\"\n",
    "Recorro la lista de años proporcionada para imprimir por un lado el resultado de mi función y,\n",
    "al mismo tiempo, la implementada en calendar.isleap. De esta forma puedo verificarlo.\n",
    "También incluyo un assert para que en caso de que no se cumpla con algún año de la lista\n",
    "falle, indicándome el error en mi función. [C]=Implementación Custom, [P]=Implementación Python\n",
    "\"\"\"\n",
    "for year in years:\n",
    "    print(f'Year: {year} is leap?: {custom_is_leap(year,True)} [C], {calendar.isleap(year)}[P]')\n",
    "    assert custom_is_leap(year) == calendar.isleap(year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb5a898",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "# Ejercicio 2\n",
    "\n",
    "Un equipo de e-sports quiere diseñar diferentes funcionalidades para procesar información y extraer diferentes métricas utilizando la base de datos del juego de fútbol \"FIFA22\". cuyos datos se pueden encontrar en la carpeta Data/players22.csv y ha sido extraído [de este conjunto de datos.](https://www.kaggle.com/datasets/stefanoleone992/fifa-22-complete-player-dataset)\n",
    "\n",
    "- 2.1: (0,5 puntos) Dado que la empresa es inglesa tienen algunos problemas con las unidades de medida: Se pide crear dos nuevas columnas en el dataframe\n",
    "  - Una de ellas llamada \"height_inches\" (altura en pulgadas) en donde se conviertan los valores de la columna \"height_cm\" de centímetros a pulgadas (cada centímetro equivale a 0.3937 pulgadas)\n",
    "  - La otra se llamará \"weight_stones\" y se convertirán los valores de kilómetros a piedras (cada kilogramo equivale a 0,1574) piedras\n",
    "  \n",
    "- 2.2 (0,5 puntos) crear una función que se llame: \"create_dictionary_with_scores\" tome como entrada una cadena de texto en donde se indique la ubicación y el nombre del fichero \"players22.csv\" y que devuelva como parámetros de salida un diccionario cuyos valores sean el nombre corto de los jugadores y su potencial.\n",
    "\n",
    "- 2.3 (0,5 puntos) crear una función que reciva el diccionario del apartado anterior como parámetro de entrada y que devuelva otro diccionario unicamente con los nombres y los valores de los cinco jugadores con más potencial ordenados de mayor a menor.\n",
    "\n",
    "Recuerda mostrar los resultados por pantalla en cada subapartado\n",
    "\n",
    "<span style=\"font-family: Courier New; background-color: #82b74b; color: #000000; padding: 3px; \">SM</span> **(1.5 puntos)**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f08080ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T14:46:38.928804Z",
     "start_time": "2024-04-27T14:46:38.349758Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         id   short_name                   long_name  overall  potential  age  \\\n0    227246    L. Bronze  Lucia Roberta Tough Bronze       92         92   29   \n1    227316    W. Renard   Wéndèleine Thérèse Renard       92         92   30   \n2    233746   V. Miedema            Vivianne Miedema       92         93   24   \n3    227125      S. Kerr           Samantha May Kerr       91         91   27   \n4    226301    A. Morgan   Alexandra Morgan Carrasco       90         90   31   \n..      ...          ...                         ...      ...        ...  ...   \n386  261799  H. Eurlings             Hannah Eurlings       66         81   18   \n387  261856     Ana Dias  Ana Inês Costa Mendes Dias       66         75   23   \n388  263000    G. Rennie                 Gabi Rennie       66         79   19   \n389  262867     C. Nevin              Courtney Nevin       62         77   19   \n390  262868     C. Grant             Charlotte Grant       60         75   19   \n\n            dob  height_cm  weight_kg nation_position  ...  \\\n0    1991-10-28        171         67              RB  ...   \n1    1990-07-20        187         70             LCB  ...   \n2    1996-07-15        178         65              ST  ...   \n3    1993-09-10        167         55              ST  ...   \n4    1989-07-02        170         62              ST  ...   \n..          ...        ...        ...             ...  ...   \n386  2003-01-01        170         58             SUB  ...   \n387  1997-10-02        171         60             SUB  ...   \n388  2001-07-07        168         64             SUB  ...   \n389  2002-02-12        168         65             SUB  ...   \n390  2001-09-20        172         70             SUB  ...   \n\n     defending_sliding_tackle goalkeeping_diving  goalkeeping_handling  \\\n0                          89                 10                    14   \n1                          91                  7                    14   \n2                          23                 14                    16   \n3                          23                  7                    12   \n4                          27                 11                    11   \n..                        ...                ...                   ...   \n386                        34                 10                    11   \n387                        12                 12                     6   \n388                        27                  9                     7   \n389                        65                  9                    11   \n390                        60                  7                    14   \n\n     goalkeeping_kicking  goalkeeping_positioning  goalkeeping_reflexes  \\\n0                     16                        8                    15   \n1                     17                       11                    15   \n2                     17                       14                    17   \n3                      8                       16                    13   \n4                     10                       10                    11   \n..                   ...                      ...                   ...   \n386                    6                       12                     5   \n387                   11                        6                    10   \n388                    6                        5                    15   \n389                   13                       12                     7   \n390                   11                        7                    14   \n\n     goalkeeping_speed                          nation_flag_url  \\\n0                  NaN  https://cdn.sofifa.com/flags/gb-eng.png   \n1                  NaN      https://cdn.sofifa.com/flags/fr.png   \n2                  NaN      https://cdn.sofifa.com/flags/nl.png   \n3                  NaN      https://cdn.sofifa.com/flags/au.png   \n4                  NaN      https://cdn.sofifa.com/flags/us.png   \n..                 ...                                      ...   \n386                NaN      https://cdn.sofifa.com/flags/be.png   \n387                NaN      https://cdn.sofifa.com/flags/pt.png   \n388                NaN      https://cdn.sofifa.com/flags/nz.png   \n389                NaN      https://cdn.sofifa.com/flags/au.png   \n390                NaN      https://cdn.sofifa.com/flags/au.png   \n\n     height_inches  weight_stones  \n0        67.322835        10.5458  \n1        73.622047        11.0180  \n2        70.078740        10.2310  \n3        65.748031         8.6570  \n4        66.929134         9.7588  \n..             ...            ...  \n386      66.929134         9.1292  \n387      67.322835         9.4440  \n388      66.141732        10.0736  \n389      66.141732        10.2310  \n390      67.716535        11.0180  \n\n[391 rows x 59 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>short_name</th>\n      <th>long_name</th>\n      <th>overall</th>\n      <th>potential</th>\n      <th>age</th>\n      <th>dob</th>\n      <th>height_cm</th>\n      <th>weight_kg</th>\n      <th>nation_position</th>\n      <th>...</th>\n      <th>defending_sliding_tackle</th>\n      <th>goalkeeping_diving</th>\n      <th>goalkeeping_handling</th>\n      <th>goalkeeping_kicking</th>\n      <th>goalkeeping_positioning</th>\n      <th>goalkeeping_reflexes</th>\n      <th>goalkeeping_speed</th>\n      <th>nation_flag_url</th>\n      <th>height_inches</th>\n      <th>weight_stones</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>227246</td>\n      <td>L. Bronze</td>\n      <td>Lucia Roberta Tough Bronze</td>\n      <td>92</td>\n      <td>92</td>\n      <td>29</td>\n      <td>1991-10-28</td>\n      <td>171</td>\n      <td>67</td>\n      <td>RB</td>\n      <td>...</td>\n      <td>89</td>\n      <td>10</td>\n      <td>14</td>\n      <td>16</td>\n      <td>8</td>\n      <td>15</td>\n      <td>NaN</td>\n      <td>https://cdn.sofifa.com/flags/gb-eng.png</td>\n      <td>67.322835</td>\n      <td>10.5458</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>227316</td>\n      <td>W. Renard</td>\n      <td>Wéndèleine Thérèse Renard</td>\n      <td>92</td>\n      <td>92</td>\n      <td>30</td>\n      <td>1990-07-20</td>\n      <td>187</td>\n      <td>70</td>\n      <td>LCB</td>\n      <td>...</td>\n      <td>91</td>\n      <td>7</td>\n      <td>14</td>\n      <td>17</td>\n      <td>11</td>\n      <td>15</td>\n      <td>NaN</td>\n      <td>https://cdn.sofifa.com/flags/fr.png</td>\n      <td>73.622047</td>\n      <td>11.0180</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>233746</td>\n      <td>V. Miedema</td>\n      <td>Vivianne Miedema</td>\n      <td>92</td>\n      <td>93</td>\n      <td>24</td>\n      <td>1996-07-15</td>\n      <td>178</td>\n      <td>65</td>\n      <td>ST</td>\n      <td>...</td>\n      <td>23</td>\n      <td>14</td>\n      <td>16</td>\n      <td>17</td>\n      <td>14</td>\n      <td>17</td>\n      <td>NaN</td>\n      <td>https://cdn.sofifa.com/flags/nl.png</td>\n      <td>70.078740</td>\n      <td>10.2310</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>227125</td>\n      <td>S. Kerr</td>\n      <td>Samantha May Kerr</td>\n      <td>91</td>\n      <td>91</td>\n      <td>27</td>\n      <td>1993-09-10</td>\n      <td>167</td>\n      <td>55</td>\n      <td>ST</td>\n      <td>...</td>\n      <td>23</td>\n      <td>7</td>\n      <td>12</td>\n      <td>8</td>\n      <td>16</td>\n      <td>13</td>\n      <td>NaN</td>\n      <td>https://cdn.sofifa.com/flags/au.png</td>\n      <td>65.748031</td>\n      <td>8.6570</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>226301</td>\n      <td>A. Morgan</td>\n      <td>Alexandra Morgan Carrasco</td>\n      <td>90</td>\n      <td>90</td>\n      <td>31</td>\n      <td>1989-07-02</td>\n      <td>170</td>\n      <td>62</td>\n      <td>ST</td>\n      <td>...</td>\n      <td>27</td>\n      <td>11</td>\n      <td>11</td>\n      <td>10</td>\n      <td>10</td>\n      <td>11</td>\n      <td>NaN</td>\n      <td>https://cdn.sofifa.com/flags/us.png</td>\n      <td>66.929134</td>\n      <td>9.7588</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>386</th>\n      <td>261799</td>\n      <td>H. Eurlings</td>\n      <td>Hannah Eurlings</td>\n      <td>66</td>\n      <td>81</td>\n      <td>18</td>\n      <td>2003-01-01</td>\n      <td>170</td>\n      <td>58</td>\n      <td>SUB</td>\n      <td>...</td>\n      <td>34</td>\n      <td>10</td>\n      <td>11</td>\n      <td>6</td>\n      <td>12</td>\n      <td>5</td>\n      <td>NaN</td>\n      <td>https://cdn.sofifa.com/flags/be.png</td>\n      <td>66.929134</td>\n      <td>9.1292</td>\n    </tr>\n    <tr>\n      <th>387</th>\n      <td>261856</td>\n      <td>Ana Dias</td>\n      <td>Ana Inês Costa Mendes Dias</td>\n      <td>66</td>\n      <td>75</td>\n      <td>23</td>\n      <td>1997-10-02</td>\n      <td>171</td>\n      <td>60</td>\n      <td>SUB</td>\n      <td>...</td>\n      <td>12</td>\n      <td>12</td>\n      <td>6</td>\n      <td>11</td>\n      <td>6</td>\n      <td>10</td>\n      <td>NaN</td>\n      <td>https://cdn.sofifa.com/flags/pt.png</td>\n      <td>67.322835</td>\n      <td>9.4440</td>\n    </tr>\n    <tr>\n      <th>388</th>\n      <td>263000</td>\n      <td>G. Rennie</td>\n      <td>Gabi Rennie</td>\n      <td>66</td>\n      <td>79</td>\n      <td>19</td>\n      <td>2001-07-07</td>\n      <td>168</td>\n      <td>64</td>\n      <td>SUB</td>\n      <td>...</td>\n      <td>27</td>\n      <td>9</td>\n      <td>7</td>\n      <td>6</td>\n      <td>5</td>\n      <td>15</td>\n      <td>NaN</td>\n      <td>https://cdn.sofifa.com/flags/nz.png</td>\n      <td>66.141732</td>\n      <td>10.0736</td>\n    </tr>\n    <tr>\n      <th>389</th>\n      <td>262867</td>\n      <td>C. Nevin</td>\n      <td>Courtney Nevin</td>\n      <td>62</td>\n      <td>77</td>\n      <td>19</td>\n      <td>2002-02-12</td>\n      <td>168</td>\n      <td>65</td>\n      <td>SUB</td>\n      <td>...</td>\n      <td>65</td>\n      <td>9</td>\n      <td>11</td>\n      <td>13</td>\n      <td>12</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>https://cdn.sofifa.com/flags/au.png</td>\n      <td>66.141732</td>\n      <td>10.2310</td>\n    </tr>\n    <tr>\n      <th>390</th>\n      <td>262868</td>\n      <td>C. Grant</td>\n      <td>Charlotte Grant</td>\n      <td>60</td>\n      <td>75</td>\n      <td>19</td>\n      <td>2001-09-20</td>\n      <td>172</td>\n      <td>70</td>\n      <td>SUB</td>\n      <td>...</td>\n      <td>60</td>\n      <td>7</td>\n      <td>14</td>\n      <td>11</td>\n      <td>7</td>\n      <td>14</td>\n      <td>NaN</td>\n      <td>https://cdn.sofifa.com/flags/au.png</td>\n      <td>67.716535</td>\n      <td>11.0180</td>\n    </tr>\n  </tbody>\n</table>\n<p>391 rows × 59 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejercicio 2.1\n",
    "import pandas as pd\n",
    "\n",
    "# Leo el csv a través de pandas, de la misma forma que en la PEC1\n",
    "players_df = pd.read_csv(\"Data/players22.csv\")\n",
    "\"\"\"\n",
    "Añado columnas nuevas multiplicando las columnas pedidas\n",
    "por las constantes indicadas\n",
    "\"\"\"\n",
    "players_df['height_inches'] = players_df['height_cm'] / 2.54\n",
    "players_df['weight_stones'] = players_df['weight_kg'] * 0.1574\n",
    "# Podemos ver el dataframe entero con la siguiente línea\n",
    "players_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "685e75fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T14:46:38.941724Z",
     "start_time": "2024-04-27T14:46:38.929787Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'short_name': 'L. Bronze', 'potential': '92'}\n",
      "{'short_name': 'W. Renard', 'potential': '92'}\n",
      "{'short_name': 'V. Miedema', 'potential': '93'}\n",
      "{'short_name': 'S. Kerr', 'potential': '91'}\n",
      "{'short_name': 'A. Morgan', 'potential': '90'}\n",
      "{'short_name': 'D. Marozsán', 'potential': '90'}\n",
      "{'short_name': 'M. Rapinoe', 'potential': '90'}\n",
      "{'short_name': 'T. Heath', 'potential': '90'}\n",
      "{'short_name': 'C. Hansen', 'potential': '91'}\n",
      "{'short_name': 'A. Henry', 'potential': '90'}\n",
      "{'short_name': 'J. Ertz', 'potential': '89'}\n",
      "{'short_name': 'C. Sinclair', 'potential': '89'}\n",
      "{'short_name': 'E. Le Sommer', 'potential': '89'}\n",
      "{'short_name': 'L. Martens', 'potential': '89'}\n",
      "{'short_name': 'B. Sauerbrunn', 'potential': '88'}\n",
      "{'short_name': 'A. Popp', 'potential': '88'}\n",
      "{'short_name': 'F. Kirby', 'potential': '88'}\n",
      "{'short_name': 'Jenni Hermoso', 'potential': '87'}\n",
      "{'short_name': 'S. Däbritz', 'potential': '89'}\n",
      "{'short_name': 'A. Majri', 'potential': '87'}\n",
      "{'short_name': 'L. Horan', 'potential': '88'}\n",
      "{'short_name': 'K. Little', 'potential': '87'}\n",
      "{'short_name': 'C. Press', 'potential': '86'}\n",
      "{'short_name': 'A. Naeher', 'potential': '86'}\n",
      "{'short_name': 'C. Dunn', 'potential': '86'}\n",
      "{'short_name': 'S. Mewis', 'potential': '86'}\n",
      "{'short_name': 'N. Fischer', 'potential': '86'}\n",
      "{'short_name': 'C. Seger', 'potential': '86'}\n",
      "{'short_name': 'S. Bouhaddi', 'potential': '86'}\n",
      "{'short_name': \"K. O'Hara\", 'potential': '85'}\n",
      "{'short_name': 'S. Houghton', 'potential': '85'}\n",
      "{'short_name': 'M. Eriksson', 'potential': '85'}\n",
      "{'short_name': 'Alexia Putellas', 'potential': '85'}\n",
      "{'short_name': 'R. Lavelle', 'potential': '88'}\n",
      "{'short_name': 'J. Groenen', 'potential': '86'}\n",
      "{'short_name': 'I. Engen', 'potential': '90'}\n",
      "{'short_name': 'A. Harris', 'potential': '84'}\n",
      "{'short_name': 'K. Asllani', 'potential': '84'}\n",
      "{'short_name': 'L. Benkarth', 'potential': '84'}\n",
      "{'short_name': 'S. Huth', 'potential': '84'}\n",
      "{'short_name': 'K. Buchanan', 'potential': '87'}\n",
      "{'short_name': 'D. Cascarino', 'potential': '89'}\n",
      "{'short_name': 'A. Erceg', 'potential': '84'}\n",
      "{'short_name': 'S. Blackstenius', 'potential': '89'}\n",
      "{'short_name': 'D. van de Donk', 'potential': '84'}\n",
      "{'short_name': 'L. Magull', 'potential': '85'}\n",
      "{'short_name': 'G. Gwinn', 'potential': '90'}\n",
      "{'short_name': 'L. Oberdorf', 'potential': '92'}\n",
      "{'short_name': 'S. Jakobsson', 'potential': '83'}\n",
      "{'short_name': 'H. Lindahl', 'potential': '83'}\n",
      "{'short_name': 'F. Rolfö', 'potential': '83'}\n",
      "{'short_name': 'Irene Paredes', 'potential': '83'}\n",
      "{'short_name': 'J. Nobbs', 'potential': '83'}\n",
      "{'short_name': 'M. Mjelde', 'potential': '83'}\n",
      "{'short_name': 'G. Mbock', 'potential': '86'}\n",
      "{'short_name': 'K. Diani', 'potential': '84'}\n",
      "{'short_name': 'S. Schmidt', 'potential': '83'}\n",
      "{'short_name': 'K. Robles', 'potential': '83'}\n",
      "{'short_name': 'M. Pugh', 'potential': '90'}\n",
      "{'short_name': 'A. Franch', 'potential': '83'}\n",
      "{'short_name': 'S. Spitse', 'potential': '83'}\n",
      "{'short_name': 'N. Parris', 'potential': '83'}\n",
      "{'short_name': 'Miri Couto', 'potential': '83'}\n",
      "{'short_name': 'Emanuelly Barni', 'potential': '83'}\n",
      "{'short_name': 'M. Katoto', 'potential': '91'}\n",
      "{'short_name': 'A. Krieger', 'potential': '82'}\n",
      "{'short_name': 'M. Leupolz', 'potential': '82'}\n",
      "{'short_name': 'K. Hendrich', 'potential': '82'}\n",
      "{'short_name': 'Wu Haiyan', 'potential': '82'}\n",
      "{'short_name': 'C. Foord', 'potential': '83'}\n",
      "{'short_name': 'S. Catley', 'potential': '83'}\n",
      "{'short_name': 'E. White', 'potential': '82'}\n",
      "{'short_name': 'K. Minde', 'potential': '82'}\n",
      "{'short_name': 'L. Maier', 'potential': '82'}\n",
      "{'short_name': 'G. Reiten', 'potential': '82'}\n",
      "{'short_name': 'A. Lawrence', 'potential': '85'}\n",
      "{'short_name': 'D. Scott', 'potential': '82'}\n",
      "{'short_name': 'S. van Veenendaal', 'potential': '82'}\n",
      "{'short_name': 'A. Dahlkemper', 'potential': '83'}\n",
      "{'short_name': 'M. Bright', 'potential': '84'}\n",
      "{'short_name': 'L. Dallmann', 'potential': '83'}\n",
      "{'short_name': 'E. Carpenter', 'potential': '91'}\n",
      "{'short_name': 'J. Roord', 'potential': '86'}\n",
      "{'short_name': 'Jully Mutto', 'potential': '82'}\n",
      "{'short_name': 'Palomy Bastos', 'potential': '82'}\n",
      "{'short_name': 'M. Frohms', 'potential': '85'}\n",
      "{'short_name': 'K. Bühl', 'potential': '89'}\n",
      "{'short_name': 'A. Berger', 'potential': '83'}\n",
      "{'short_name': 'E. Haavi', 'potential': '81'}\n",
      "{'short_name': 'L. Williams', 'potential': '81'}\n",
      "{'short_name': 'Sandra Paños', 'potential': '83'}\n",
      "{'short_name': 'Mapi León', 'potential': '86'}\n",
      "{'short_name': 'H. Glas', 'potential': '81'}\n",
      "{'short_name': 'L. Schüller', 'potential': '87'}\n",
      "{'short_name': 'Letinha Lia', 'potential': '81'}\n",
      "{'short_name': 'Isinha Macapá', 'potential': '81'}\n",
      "{'short_name': 'Becky Saudera', 'potential': '81'}\n",
      "{'short_name': 'S. Lohmann', 'potential': '89'}\n",
      "{'short_name': 'M. Hegering', 'potential': '81'}\n",
      "{'short_name': 'T. Wullaert', 'potential': '81'}\n",
      "{'short_name': 'Wang Shuang', 'potential': '83'}\n",
      "{'short_name': 'Tang Jiali', 'potential': '82'}\n",
      "{'short_name': 'E. Kellond-Knight', 'potential': '80'}\n",
      "{'short_name': 'K. Bardsley', 'potential': '80'}\n",
      "{'short_name': 'A. Greenwood', 'potential': '80'}\n",
      "{'short_name': 'J. Scott', 'potential': '80'}\n",
      "{'short_name': 'C. Telford', 'potential': '80'}\n",
      "{'short_name': 'J. Beckie', 'potential': '80'}\n",
      "{'short_name': 'S. Labbé', 'potential': '80'}\n",
      "{'short_name': 'M. Torrent', 'potential': '80'}\n",
      "{'short_name': 'E. Sonnett', 'potential': '81'}\n",
      "{'short_name': 'A. Riley', 'potential': '80'}\n",
      "{'short_name': 'S. van der Gragt', 'potential': '80'}\n",
      "{'short_name': 'F. Rauch', 'potential': '85'}\n",
      "{'short_name': 'R. Daly', 'potential': '80'}\n",
      "{'short_name': 'G. Geyoro', 'potential': '89'}\n",
      "{'short_name': 'K. Sheridan', 'potential': '83'}\n",
      "{'short_name': 'L. Beerensteyn', 'potential': '84'}\n",
      "{'short_name': 'Peng Shimeng', 'potential': '85'}\n",
      "{'short_name': 'Julininha Ruiz', 'potential': '80'}\n",
      "{'short_name': 'Karole Pombal', 'potential': '80'}\n",
      "{'short_name': 'L. Freigang', 'potential': '85'}\n",
      "{'short_name': 'J. Cayman', 'potential': '80'}\n",
      "{'short_name': 'Liu Shanshan', 'potential': '79'}\n",
      "{'short_name': 'E. van Egmond', 'potential': '79'}\n",
      "{'short_name': 'H. Raso', 'potential': '79'}\n",
      "{'short_name': 'D. Stokes', 'potential': '79'}\n",
      "{'short_name': 'S. Mayor', 'potential': '79'}\n",
      "{'short_name': 'R. Percival', 'potential': '79'}\n",
      "{'short_name': 'S. van de Sanden', 'potential': '79'}\n",
      "{'short_name': 'D. Janssen', 'potential': '80'}\n",
      "{'short_name': 'E. Perisset', 'potential': '81'}\n",
      "{'short_name': 'K. Walsh', 'potential': '88'}\n",
      "{'short_name': 'C. Emslie', 'potential': '79'}\n",
      "{'short_name': 'Bianca Revelia', 'potential': '79'}\n",
      "{'short_name': 'Becky Redela', 'potential': '79'}\n",
      "{'short_name': 'J. Beattie', 'potential': '79'}\n",
      "{'short_name': 'C. Weir', 'potential': '82'}\n",
      "{'short_name': 'T. De Caigny', 'potential': '84'}\n",
      "{'short_name': 'Li Ying', 'potential': '78'}\n",
      "{'short_name': 'Ma Jun', 'potential': '78'}\n",
      "{'short_name': 'A. Ilestedt', 'potential': '79'}\n",
      "{'short_name': 'A. Kennedy', 'potential': '81'}\n",
      "{'short_name': 'K. Gorry', 'potential': '78'}\n",
      "{'short_name': 'Marta Corredera', 'potential': '78'}\n",
      "{'short_name': 'J. Fleming', 'potential': '84'}\n",
      "{'short_name': 'Amanda Sampedro', 'potential': '78'}\n",
      "{'short_name': 'E. Nayler', 'potential': '79'}\n",
      "{'short_name': 'S. Karchaoui', 'potential': '82'}\n",
      "{'short_name': 'M. van Dongen', 'potential': '78'}\n",
      "{'short_name': 'A. Dekker', 'potential': '78'}\n",
      "{'short_name': 'Patri Guijarro', 'potential': '86'}\n",
      "{'short_name': 'Z. Mušović', 'potential': '84'}\n",
      "{'short_name': 'G. Stanway', 'potential': '89'}\n",
      "{'short_name': 'B. Mead', 'potential': '79'}\n",
      "{'short_name': 'E. Cuthbert', 'potential': '87'}\n",
      "{'short_name': 'L. Williamson', 'potential': '83'}\n",
      "{'short_name': 'Wang Shanshan', 'potential': '77'}\n",
      "{'short_name': 'Zhang Xin', 'potential': '77'}\n",
      "{'short_name': 'O. Schough', 'potential': '77'}\n",
      "{'short_name': 'E. Rubensson', 'potential': '77'}\n",
      "{'short_name': 'C. Polkinghorne', 'potential': '77'}\n",
      "{'short_name': 'T. Yallop', 'potential': '77'}\n",
      "{'short_name': 'Virginia Torrecilla', 'potential': '80'}\n",
      "{'short_name': 'Vicky Losada', 'potential': '77'}\n",
      "{'short_name': 'C. Fiskerstrand', 'potential': '81'}\n",
      "{'short_name': 'E. McLeod', 'potential': '77'}\n",
      "{'short_name': 'K. Bowen', 'potential': '78'}\n",
      "{'short_name': 'J. Andersson', 'potential': '77'}\n",
      "{'short_name': 'C. Krueger', 'potential': '77'}\n",
      "{'short_name': 'Mariona', 'potential': '80'}\n",
      "{'short_name': 'Aitana Bonmatí', 'potential': '85'}\n",
      "{'short_name': 'V. Risa', 'potential': '80'}\n",
      "{'short_name': 'Lin Yuping', 'potential': '77'}\n",
      "{'short_name': 'Melinda Goiás', 'potential': '77'}\n",
      "{'short_name': 'E. Mitchell', 'potential': '77'}\n",
      "{'short_name': 'L. Evans', 'potential': '77'}\n",
      "{'short_name': 'A. Nouwen', 'potential': '83'}\n",
      "{'short_name': 'N. Björn', 'potential': '84'}\n",
      "{'short_name': 'E. Roebuck', 'potential': '86'}\n",
      "{'short_name': 'B. England', 'potential': '78'}\n",
      "{'short_name': 'Zhai Qingwei', 'potential': '82'}\n",
      "{'short_name': 'Cláudia Neto', 'potential': '77'}\n",
      "{'short_name': 'Zhang Rui', 'potential': '76'}\n",
      "{'short_name': 'Gu Yasha', 'potential': '76'}\n",
      "{'short_name': 'V. Asseyi', 'potential': '76'}\n",
      "{'short_name': 'K. Dali', 'potential': '76'}\n",
      "{'short_name': 'A. Chapman', 'potential': '76'}\n",
      "{'short_name': 'Leila Ouahabi', 'potential': '76'}\n",
      "{'short_name': 'K. van Es', 'potential': '76'}\n",
      "{'short_name': 'S. Zadorsky', 'potential': '76'}\n",
      "{'short_name': 'A. Tounkara', 'potential': '79'}\n",
      "{'short_name': 'T. Knaak', 'potential': '76'}\n",
      "{'short_name': 'Cecil Sendela', 'potential': '76'}\n",
      "{'short_name': 'Zoe Tocantins', 'potential': '76'}\n",
      "{'short_name': 'Isaby Camila', 'potential': '76'}\n",
      "{'short_name': 'Niccole Cintra', 'potential': '76'}\n",
      "{'short_name': 'K. Sævik', 'potential': '79'}\n",
      "{'short_name': 'L. Alexander', 'potential': '77'}\n",
      "{'short_name': 'R. Corsie', 'potential': '76'}\n",
      "{'short_name': 'J. Falk', 'potential': '77'}\n",
      "{'short_name': 'A. Anvegård', 'potential': '82'}\n",
      "{'short_name': 'Li Mengwen', 'potential': '78'}\n",
      "{'short_name': 'J. Brand', 'potential': '84'}\n",
      "{'short_name': 'J. Biesmans', 'potential': '78'}\n",
      "{'short_name': 'Carole Costa', 'potential': '76'}\n",
      "{'short_name': 'Ana Borges', 'potential': '76'}\n",
      "{'short_name': 'Yang Li', 'potential': '75'}\n",
      "{'short_name': 'Han Peng', 'potential': '75'}\n",
      "{'short_name': 'Quinn', 'potential': '78'}\n",
      "{'short_name': 'Ivana Andrés', 'potential': '78'}\n",
      "{'short_name': 'M. Arnold', 'potential': '79'}\n",
      "{'short_name': 'E. Alvarado', 'potential': '85'}\n",
      "{'short_name': 'Pang Fengyue', 'potential': '75'}\n",
      "{'short_name': 'C. Logarzo', 'potential': '77'}\n",
      "{'short_name': 'Andrea Pereira', 'potential': '77'}\n",
      "{'short_name': 'Esther González', 'potential': '75'}\n",
      "{'short_name': 'L. Utland', 'potential': '75'}\n",
      "{'short_name': 'M. Moore', 'potential': '80'}\n",
      "{'short_name': 'A. Longo', 'potential': '75'}\n",
      "{'short_name': 'I. Kaagman', 'potential': '77'}\n",
      "{'short_name': 'N. Prince', 'potential': '76'}\n",
      "{'short_name': 'F. Maanum', 'potential': '85'}\n",
      "{'short_name': 'R. Jansen', 'potential': '75'}\n",
      "{'short_name': 'S. Durand', 'potential': '76'}\n",
      "{'short_name': 'Lucía García', 'potential': '84'}\n",
      "{'short_name': 'K. Snoeijs', 'potential': '79'}\n",
      "{'short_name': 'Iris Vieirinha', 'potential': '75'}\n",
      "{'short_name': 'Jandinha Kenedy', 'potential': '75'}\n",
      "{'short_name': 'S. Howard', 'potential': '76'}\n",
      "{'short_name': 'F. Brown', 'potential': '76'}\n",
      "{'short_name': 'K. Smith', 'potential': '76'}\n",
      "{'short_name': 'Nahikari', 'potential': '79'}\n",
      "{'short_name': 'M. Janogy', 'potential': '79'}\n",
      "{'short_name': 'V. Gilles', 'potential': '79'}\n",
      "{'short_name': 'Ona Batlle', 'potential': '83'}\n",
      "{'short_name': 'C. Kelly', 'potential': '84'}\n",
      "{'short_name': 'L. Hemp', 'potential': '88'}\n",
      "{'short_name': 'Yao Lingwei', 'potential': '79'}\n",
      "{'short_name': 'L. Deloose', 'potential': '75'}\n",
      "{'short_name': 'D. Philtjens', 'potential': '75'}\n",
      "{'short_name': 'Dolores Silva', 'potential': '75'}\n",
      "{'short_name': 'Sílvia Rebelo', 'potential': '75'}\n",
      "{'short_name': 'C. Macario', 'potential': '75'}\n",
      "{'short_name': 'F. Angeldahl', 'potential': '82'}\n",
      "{'short_name': 'L. Hurtig', 'potential': '75'}\n",
      "{'short_name': 'K. Simon', 'potential': '74'}\n",
      "{'short_name': 'A. Leon', 'potential': '74'}\n",
      "{'short_name': 'C. Bilbault', 'potential': '74'}\n",
      "{'short_name': 'M. Thorisdottir', 'potential': '75'}\n",
      "{'short_name': 'L. Geurts', 'potential': '74'}\n",
      "{'short_name': 'M. Purce', 'potential': '77'}\n",
      "{'short_name': 'Kla Elisinha', 'potential': '74'}\n",
      "{'short_name': 'Giovanny Bia', 'potential': '74'}\n",
      "{'short_name': 'Magi Bardini', 'potential': '74'}\n",
      "{'short_name': 'J. Ross', 'potential': '74'}\n",
      "{'short_name': 'L. Clelland', 'potential': '74'}\n",
      "{'short_name': 'C. Murray', 'potential': '74'}\n",
      "{'short_name': 'J. Love', 'potential': '74'}\n",
      "{'short_name': 'H. Lauder', 'potential': '74'}\n",
      "{'short_name': 'P. Peyraud-Magnin', 'potential': '75'}\n",
      "{'short_name': 'Alba Redondo', 'potential': '79'}\n",
      "{'short_name': 'L. Wilms', 'potential': '83'}\n",
      "{'short_name': 'Marta Cardona', 'potential': '75'}\n",
      "{'short_name': 'S. Kleinherne', 'potential': '84'}\n",
      "{'short_name': 'Misa', 'potential': '81'}\n",
      "{'short_name': 'A. Cervantes', 'potential': '74'}\n",
      "{'short_name': 'K. Missipo', 'potential': '79'}\n",
      "{'short_name': 'Jéssica Silva', 'potential': '77'}\n",
      "{'short_name': 'S. Jensen', 'potential': '77'}\n",
      "{'short_name': 'M. Sánchez', 'potential': '76'}\n",
      "{'short_name': 'R. White', 'potential': '73'}\n",
      "{'short_name': 'D. Kerkdijk', 'potential': '75'}\n",
      "{'short_name': 'V. Esson', 'potential': '73'}\n",
      "{'short_name': 'K. Leine', 'potential': '78'}\n",
      "{'short_name': 'O. Chance', 'potential': '73'}\n",
      "{'short_name': 'Rafaelly Paraná', 'potential': '73'}\n",
      "{'short_name': 'L. Arnot', 'potential': '77'}\n",
      "{'short_name': 'C. Arthur', 'potential': '76'}\n",
      "{'short_name': 'L. Crichton', 'potential': '73'}\n",
      "{'short_name': 'E. Laurent', 'potential': '85'}\n",
      "{'short_name': 'N. Docherty', 'potential': '73'}\n",
      "{'short_name': 'D. Espinosa', 'potential': '84'}\n",
      "{'short_name': 'J. Huitema', 'potential': '84'}\n",
      "{'short_name': 'Yao Wei', 'potential': '79'}\n",
      "{'short_name': 'Laia Aleixandri', 'potential': '84'}\n",
      "{'short_name': 'P. Morroni', 'potential': '80'}\n",
      "{'short_name': 'J. López', 'potential': '79'}\n",
      "{'short_name': 'É. Viens', 'potential': '77'}\n",
      "{'short_name': 'J. Vanhaevermaet', 'potential': '73'}\n",
      "{'short_name': 'L. De Neve', 'potential': '76'}\n",
      "{'short_name': 'M. Minnaert', 'potential': '79'}\n",
      "{'short_name': 'L. Onzia', 'potential': '73'}\n",
      "{'short_name': 'Patrícia Morais', 'potential': '73'}\n",
      "{'short_name': 'Carolina Mendes', 'potential': '73'}\n",
      "{'short_name': 'E. Toone', 'potential': '83'}\n",
      "{'short_name': 'H. Bennison', 'potential': '90'}\n",
      "{'short_name': 'Li Jiayue', 'potential': '72'}\n",
      "{'short_name': 'E. Thorsnes', 'potential': '72'}\n",
      "{'short_name': 'C. Jaramillo', 'potential': '72'}\n",
      "{'short_name': 'Bi Xiaolin', 'potential': '72'}\n",
      "{'short_name': 'E. Gielnik', 'potential': '72'}\n",
      "{'short_name': 'S. Hansen', 'potential': '75'}\n",
      "{'short_name': 'A. Green', 'potential': '72'}\n",
      "{'short_name': 'H. Wilkinson', 'potential': '72'}\n",
      "{'short_name': 'C. Bott', 'potential': '75'}\n",
      "{'short_name': 'L. Agnew', 'potential': '74'}\n",
      "{'short_name': 'D. Rose', 'potential': '81'}\n",
      "{'short_name': 'S. Woeller', 'potential': '72'}\n",
      "{'short_name': 'R. Bernal', 'potential': '75'}\n",
      "{'short_name': 'L. Kop', 'potential': '78'}\n",
      "{'short_name': 'V. Pelova', 'potential': '80'}\n",
      "{'short_name': 'Licinha Bardini', 'potential': '72'}\n",
      "{'short_name': 'A. Eikeland', 'potential': '73'}\n",
      "{'short_name': 'J. Roddar', 'potential': '72'}\n",
      "{'short_name': 'A. González', 'potential': '84'}\n",
      "{'short_name': 'J. Odeurs', 'potential': '77'}\n",
      "{'short_name': 'N. Evrard', 'potential': '76'}\n",
      "{'short_name': 'D. Vanmechelen', 'potential': '80'}\n",
      "{'short_name': 'C. Vande Velde', 'potential': '77'}\n",
      "{'short_name': 'Tatiana Pinto', 'potential': '73'}\n",
      "{'short_name': 'Diana Silva', 'potential': '75'}\n",
      "{'short_name': 'Andreia Norton', 'potential': '77'}\n",
      "{'short_name': 'Fátima Pinto', 'potential': '77'}\n",
      "{'short_name': 'K. Cooney-Cross', 'potential': '88'}\n",
      "{'short_name': 'A. Cook', 'potential': '76'}\n",
      "{'short_name': 'Song Duan', 'potential': '74'}\n",
      "{'short_name': 'N. Antonio', 'potential': '75'}\n",
      "{'short_name': 'B. Hassett', 'potential': '71'}\n",
      "{'short_name': 'T. Hansen', 'potential': '80'}\n",
      "{'short_name': 'K. Rood', 'potential': '71'}\n",
      "{'short_name': 'M. Kelly', 'potential': '71'}\n",
      "{'short_name': 'J. Fife', 'potential': '76'}\n",
      "{'short_name': 'L. Staniforth', 'potential': '71'}\n",
      "{'short_name': 'Luo Guiping', 'potential': '71'}\n",
      "{'short_name': 'É. De Almeida', 'potential': '79'}\n",
      "{'short_name': 'I. González', 'potential': '71'}\n",
      "{'short_name': 'Joana Marchão', 'potential': '76'}\n",
      "{'short_name': 'Ana Capeta', 'potential': '80'}\n",
      "{'short_name': 'Inês Pereira', 'potential': '79'}\n",
      "{'short_name': 'J. Montoya', 'potential': '80'}\n",
      "{'short_name': 'J. Orejel', 'potential': '74'}\n",
      "{'short_name': 'S. Lynn', 'potential': '70'}\n",
      "{'short_name': 'C. Kvamme', 'potential': '73'}\n",
      "{'short_name': 'E. Kullberg', 'potential': '71'}\n",
      "{'short_name': 'S. Van Belle', 'potential': '78'}\n",
      "{'short_name': 'A. Tysiak', 'potential': '78'}\n",
      "{'short_name': 'C. Tison', 'potential': '76'}\n",
      "{'short_name': 'Telma Encarnação', 'potential': '78'}\n",
      "{'short_name': 'Kika Nazareth', 'potential': '82'}\n",
      "{'short_name': 'Rute Costa', 'potential': '73'}\n",
      "{'short_name': 'A. Harrison', 'potential': '72'}\n",
      "{'short_name': 'C. Ferral', 'potential': '69'}\n",
      "{'short_name': 'B. Campos', 'potential': '72'}\n",
      "{'short_name': 'T. Åsland', 'potential': '72'}\n",
      "{'short_name': 'M. Fowler', 'potential': '86'}\n",
      "{'short_name': 'D. Evangelista', 'potential': '72'}\n",
      "{'short_name': 'M. Cadena', 'potential': '74'}\n",
      "{'short_name': 'E. Cascarino', 'potential': '78'}\n",
      "{'short_name': 'L. Wajnblum', 'potential': '73'}\n",
      "{'short_name': 'Andreia Jacinto', 'potential': '79'}\n",
      "{'short_name': 'Andreia Faria', 'potential': '79'}\n",
      "{'short_name': 'Alícia Correia', 'potential': '81'}\n",
      "{'short_name': 'K. Rodríguez', 'potential': '77'}\n",
      "{'short_name': 'S. Smith', 'potential': '78'}\n",
      "{'short_name': 'A. Rodríguez', 'potential': '73'}\n",
      "{'short_name': 'A. Phillips', 'potential': '68'}\n",
      "{'short_name': 'P. Satchell', 'potential': '75'}\n",
      "{'short_name': 'J. Hellstrom', 'potential': '68'}\n",
      "{'short_name': 'K. Roestbakken', 'potential': '84'}\n",
      "{'short_name': 'C. Bunge', 'potential': '78'}\n",
      "{'short_name': 'G. Pettersen', 'potential': '68'}\n",
      "{'short_name': 'M. Villeda', 'potential': '78'}\n",
      "{'short_name': 'I. Iliano', 'potential': '73'}\n",
      "{'short_name': 'D. Lemey', 'potential': '72'}\n",
      "{'short_name': 'M. Coutereels', 'potential': '68'}\n",
      "{'short_name': 'Catarina Amado', 'potential': '78'}\n",
      "{'short_name': 'S. Morton', 'potential': '74'}\n",
      "{'short_name': 'A. Mikalsen', 'potential': '72'}\n",
      "{'short_name': 'N. Stratford', 'potential': '67'}\n",
      "{'short_name': 'J. Blakstad', 'potential': '84'}\n",
      "{'short_name': 'M. Delgadillo', 'potential': '70'}\n",
      "{'short_name': 'S. Skilton', 'potential': '66'}\n",
      "{'short_name': 'T. Micah', 'potential': '75'}\n",
      "{'short_name': 'D. García', 'potential': '76'}\n",
      "{'short_name': 'M. van der Meer', 'potential': '78'}\n",
      "{'short_name': 'H. Eurlings', 'potential': '81'}\n",
      "{'short_name': 'Ana Dias', 'potential': '75'}\n",
      "{'short_name': 'G. Rennie', 'potential': '79'}\n",
      "{'short_name': 'C. Nevin', 'potential': '77'}\n",
      "{'short_name': 'C. Grant', 'potential': '75'}\n"
     ]
    }
   ],
   "source": [
    "# Ejercicio 2.2\n",
    "def create_dictionary_with_scores(path:str) -> list: \n",
    "    \"\"\"\n",
    "    Crea un diccionario a partir del path proporcionado\n",
    "    buscando los valores short_name y potential para \n",
    "    cada fila.\n",
    "    \n",
    "    :param path: Ruta del csv a leer\n",
    "    :return: lista con los valores leidos\n",
    "    \"\"\"\n",
    "    dicts = []\n",
    "    # Es necesario el encoding para poder leer el fichero\n",
    "    with open(path, 'r', encoding='utf-8') as file:\n",
    "        # Me salto la primera línea para no leer los nombres de las tablas\n",
    "        next(file)\n",
    "        # Leo línea por línea\n",
    "        for lane in file:\n",
    "            # Divido los campos de cada línea por el carácter ','\n",
    "            valores = lane.strip().split(',')\n",
    "            # Me quedo solo con los valores de las columnas 1 y 4\n",
    "            short_name = valores[1]\n",
    "            potential = valores[4]\n",
    "            # Meto el diccionario creado en la lista de diccionarios\n",
    "            dicts.append({'short_name': short_name, 'potential': potential})\n",
    "    return dicts\n",
    "\n",
    "# Ruta del archivo CSV\n",
    "ruta_archivo = \"Data/players22.csv\"\n",
    "\n",
    "# Llamo a la función para obtener los resultados\n",
    "resultados = create_dictionary_with_scores(ruta_archivo)\n",
    "\n",
    "# Imprime los diccionarios resultantes\n",
    "for dicc in resultados:\n",
    "    print(dicc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e39577d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T14:46:38.952038Z",
     "start_time": "2024-04-27T14:46:38.945618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V. Miedema: 93\n",
      "L. Bronze: 92\n",
      "W. Renard: 92\n",
      "L. Oberdorf: 92\n",
      "S. Kerr: 91\n"
     ]
    }
   ],
   "source": [
    "# Ejercicio 2.3\n",
    "def get_most_powerful_players(players_dicc) -> list:\n",
    "    \"\"\"\n",
    "    Ordena el diccionario de input por el campo 'potential' \n",
    "    y devuelve los 5 primeros valores\n",
    "    :param players_dicc: diccionario de entrada\n",
    "    :return: sub diccionario de respuesta con los 5 primeros \n",
    "    que ordenados\n",
    "    \"\"\"\n",
    "    # Se puede ordenar la lista de diccionarios por su columna potencial\n",
    "    players_dicc_sorted = sorted(players_dicc, key=lambda x: int(x['potential']), reverse=True)\n",
    "    # Y luego basta con devolver los cinco primeros\n",
    "    return players_dicc_sorted[:5]\n",
    "\n",
    "# Hago el cálculo llamando a la función y lo imprimo\n",
    "most_powerful_players = get_most_powerful_players(resultados)\n",
    "for player in most_powerful_players:\n",
    "    print(f\"{player['short_name']}: {player['potential']}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T14:46:38.956939Z",
     "start_time": "2024-04-27T14:46:38.953981Z"
    }
   },
   "id": "50c9875c8460b25",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "ee8fd7db",
   "metadata": {},
   "source": [
    "# Ejercicio 3\n",
    "\n",
    "Nos piden también crear una función que recorra el archivo `players22.csv`\n",
    "\n",
    "La función, llamada `create_dictionary`, recibirá como *entrada* :\n",
    "\n",
    "- La ruta que contiene el archivo de datos en formato *.csv*.\n",
    "- El nombre de una columna \"col\" que contiene datos numéricos del archivo\n",
    "\n",
    "La *salida* será un diccionario donde:\n",
    "\n",
    "- Cada clave contendrá el identificador de un País. Por ejemplo, gb-eng, nl o fr. Nota: Esta información la tiene disponible como parte de la columna \"nation_flag_url\" y es parte del trabajo de la PAC extraerla correctamente.\n",
    "\n",
    "- El valor correspondiente a cada clave será una lista de tuplas. La lista contendrá todos los jugadores que sean de la nacionalidad indicada en la clave. En cada posición de la lista se guardará una tupla con dos elementos: (short_name, col) donde encontraremos el contenido de la columna \"short_name\" y de la columna col indicada en la llamada de la función.\n",
    " \n",
    "Por ejemplo, si llamásemos la función con la ruta de archivo correcta y col = \"goalkeeping_diving\", el valor asociado a la clave \"cn\" sería:\n",
    "\n",
    "\\[('Wu Haiyan', '7'), ('Wang Shuang', '15'), ..., ('Luo Guiping', '8')\\]\n",
    "\n",
    "Notad que presentamos aquí sólo parte de la lista y que el orden dentro de la lista no es importante, por lo que es posible que obtengáis la misma lista con las tuplas en un orden diferente.\n",
    "\n",
    "**Notas importantes:**\n",
    "\n",
    "1) La información de la nacionalidad de cada jugadora se encuentra en la última columna (nation_flag_url). Notad también que esta columna contiene información que no debe ser parte de las claves de su diccionario.\n",
    "\n",
    "2) Utilizad los principios de **programación funcional** que hemos visto en teoría para resolver este ejercicio y **expresiones regulares** para extraer la nacionalidad de la url que la contiene.\n",
    "\n",
    "3) Ocasionalmente, es posible que alguno de los datos que se piden no esté disponible en el archivo. En este caso, será necesario que la posición correspondiente a este dato en la tupla de la jugadora contenga un string vacío \"\". Por este hecho, entre otros, **se desaconseja el uso de la librería Pandas para resolver este ejercicio.**\n",
    "\n",
    "4) En este notebook encontraréis una celda extra con código que puede utilizar para comprobar que la función se ejecuta correctamente con unas entradas concretas. Tened en cuenta que esto es solo una ayuda y que **es vuestra responsabilidad testar el código de manera adecuada.** En concreto, durante la corrección se llamará el código con otros parámetros.\n",
    "\n",
    "<span style=\"font-family: Courier New; background-color: #ffcc5c; color: #000000; padding: 3px; \">EG</span> **(2.5 puntos)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00cb2e02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T14:46:38.984658Z",
     "start_time": "2024-04-27T14:46:38.958864Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'gb-eng': [('L. Bronze', '1991-10-28'),\n  ('F. Kirby', '1993-06-29'),\n  ('S. Houghton', '1988-04-23'),\n  ('J. Nobbs', '1992-12-08'),\n  ('N. Parris', '1994-03-10'),\n  ('E. White', '1989-05-09'),\n  ('M. Bright', '1993-08-21'),\n  ('K. Bardsley', '1984-10-14'),\n  ('A. Greenwood', '1993-09-07'),\n  ('J. Scott', '1987-02-02'),\n  ('C. Telford', '1987-07-07'),\n  ('R. Daly', '1991-12-06'),\n  ('D. Stokes', '1991-12-12'),\n  ('K. Walsh', '1997-04-08'),\n  ('G. Stanway', '1999-01-03'),\n  ('B. Mead', '1995-05-09'),\n  ('L. Williamson', '1997-03-29'),\n  ('E. Roebuck', '1999-09-23'),\n  ('B. England', '1994-06-03'),\n  ('C. Kelly', '1998-01-15'),\n  ('L. Hemp', '2000-08-07'),\n  ('E. Toone', '1999-09-02'),\n  ('L. Staniforth', '1992-10-02')],\n 'fr': [('W. Renard', '1990-07-20'),\n  ('A. Henry', '1989-09-28'),\n  ('E. Le Sommer', '1989-05-18'),\n  ('A. Majri', '1993-01-25'),\n  ('S. Bouhaddi', '1986-10-17'),\n  ('D. Cascarino', '1997-02-05'),\n  ('G. Mbock', '1995-02-26'),\n  ('K. Diani', '1995-04-01'),\n  ('M. Katoto', '1998-11-01'),\n  ('M. Torrent', '1992-04-17'),\n  ('G. Geyoro', '1997-07-02'),\n  ('E. Perisset', '1994-12-24'),\n  ('S. Karchaoui', '1996-01-26'),\n  ('V. Asseyi', '1993-11-20'),\n  ('K. Dali', '1991-07-31'),\n  ('A. Tounkara', '1995-03-16'),\n  ('S. Durand', '1994-11-20'),\n  ('C. Bilbault', '1990-06-05'),\n  ('P. Peyraud-Magnin', '1992-03-17'),\n  ('E. Laurent', '1998-11-04'),\n  ('P. Morroni', '1997-10-15'),\n  ('É. De Almeida', '1998-01-11'),\n  ('E. Cascarino', '1997-02-05')],\n 'nl': [('V. Miedema', '1996-07-15'),\n  ('L. Martens', '1992-12-16'),\n  ('J. Groenen', '1994-12-17'),\n  ('D. van de Donk', '1991-08-05'),\n  ('S. Spitse', '1990-05-29'),\n  ('S. van Veenendaal', '1990-04-03'),\n  ('J. Roord', '1997-04-22'),\n  ('S. van der Gragt', '1992-08-16'),\n  ('L. Beerensteyn', '1996-10-11'),\n  ('S. van de Sanden', '1992-10-02'),\n  ('D. Janssen', '1995-01-17'),\n  ('M. van Dongen', '1993-02-11'),\n  ('A. Dekker', '1986-11-15'),\n  ('A. Nouwen', '1999-03-09'),\n  ('K. van Es', '1991-10-11'),\n  ('I. Kaagman', '1996-04-17'),\n  ('R. Jansen', '1990-12-07'),\n  ('K. Snoeijs', '1996-08-01'),\n  ('L. Geurts', '1986-01-12'),\n  ('L. Wilms', '2000-10-03'),\n  ('D. Kerkdijk', '1996-05-01'),\n  ('L. Kop', '1998-03-17'),\n  ('V. Pelova', '1999-06-03')],\n 'au': [('S. Kerr', '1993-09-10'),\n  ('C. Foord', '1994-11-11'),\n  ('S. Catley', '1994-01-26'),\n  ('E. Carpenter', '2000-04-28'),\n  ('L. Williams', '1988-05-13'),\n  ('E. Kellond-Knight', '1990-08-10'),\n  ('E. van Egmond', '1993-07-12'),\n  ('H. Raso', '1994-09-05'),\n  ('A. Kennedy', '1995-01-21'),\n  ('K. Gorry', '1992-08-13'),\n  ('C. Polkinghorne', '1989-02-01'),\n  ('T. Yallop', '1991-06-16'),\n  ('M. Arnold', '1994-02-25'),\n  ('C. Logarzo', '1994-12-22'),\n  ('K. Simon', '1991-06-25'),\n  ('E. Gielnik', '1992-05-13'),\n  ('K. Cooney-Cross', '2002-02-15'),\n  ('A. Harrison', '1996-04-21'),\n  ('M. Fowler', '2003-02-14'),\n  ('K. Roestbakken', '2001-01-17'),\n  ('T. Micah', '1997-10-20'),\n  ('C. Nevin', '2002-02-12'),\n  ('C. Grant', '2001-09-20')],\n 'us': [('A. Morgan', '1989-07-02'),\n  ('M. Rapinoe', '1985-07-05'),\n  ('T. Heath', '1988-05-29'),\n  ('J. Ertz', '1992-04-06'),\n  ('B. Sauerbrunn', '1985-06-06'),\n  ('L. Horan', '1994-05-26'),\n  ('C. Press', '1988-12-29'),\n  ('A. Naeher', '1988-04-20'),\n  ('C. Dunn', '1992-07-03'),\n  ('S. Mewis', '1992-10-09'),\n  (\"K. O'Hara\", '1988-08-04'),\n  ('R. Lavelle', '1995-05-14'),\n  ('A. Harris', '1985-10-19'),\n  ('M. Pugh', '1998-04-29'),\n  ('A. Franch', '1990-11-12'),\n  ('A. Krieger', '1984-07-28'),\n  ('A. Dahlkemper', '1993-05-13'),\n  ('E. Sonnett', '1993-11-25'),\n  ('C. Krueger', '1990-08-23'),\n  ('C. Macario', '1990-10-04'),\n  ('M. Purce', '1995-09-18'),\n  ('A. Cook', '1997-04-11'),\n  ('S. Smith', '2000-08-10')],\n 'de': [('D. Marozsán', '1992-04-18'),\n  ('A. Popp', '1991-04-06'),\n  ('S. Däbritz', '1995-02-15'),\n  ('L. Benkarth', '1992-10-14'),\n  ('S. Huth', '1991-01-25'),\n  ('L. Magull', '1994-08-15'),\n  ('G. Gwinn', '1999-07-02'),\n  ('L. Oberdorf', '2001-12-19'),\n  ('M. Leupolz', '1994-04-14'),\n  ('K. Hendrich', '1992-04-06'),\n  ('L. Maier', '1992-09-29'),\n  ('L. Dallmann', '1994-09-02'),\n  ('M. Frohms', '1995-01-28'),\n  ('K. Bühl', '2000-12-07'),\n  ('A. Berger', '1990-10-09'),\n  ('L. Schüller', '1997-11-12'),\n  ('S. Lohmann', '2000-06-19'),\n  ('M. Hegering', '1990-04-17'),\n  ('F. Rauch', '1996-04-30'),\n  ('L. Freigang', '1998-02-11'),\n  ('T. Knaak', '1991-01-24'),\n  ('J. Brand', '2002-10-16'),\n  ('S. Kleinherne', '2000-04-12')],\n 'no': [('C. Hansen', '1995-02-18'),\n  ('I. Engen', '1998-04-29'),\n  ('M. Mjelde', '1989-11-06'),\n  ('K. Minde', '1992-08-08'),\n  ('G. Reiten', '1994-07-26'),\n  ('E. Haavi', '1992-06-16'),\n  ('C. Fiskerstrand', '1996-03-20'),\n  ('V. Risa', '1995-07-13'),\n  ('K. Sævik', '1996-03-24'),\n  ('L. Utland', '1992-09-19'),\n  ('F. Maanum', '1999-07-16'),\n  ('M. Thorisdottir', '1993-06-05'),\n  ('S. Jensen', '1996-02-15'),\n  ('K. Leine', '1996-08-06'),\n  ('E. Thorsnes', '1988-08-14'),\n  ('S. Hansen', '1995-08-12'),\n  ('A. Eikeland', '1995-08-26'),\n  ('T. Hansen', '1997-08-04'),\n  ('C. Kvamme', '1995-09-11'),\n  ('T. Åsland', '1995-08-26'),\n  ('G. Pettersen', '1991-08-22'),\n  ('A. Mikalsen', '1996-03-21'),\n  ('J. Blakstad', '2001-08-27')],\n 'ca': [('C. Sinclair', '1983-06-12'),\n  ('K. Buchanan', '1995-11-05'),\n  ('S. Schmidt', '1988-06-28'),\n  ('A. Lawrence', '1995-06-11'),\n  ('D. Scott', '1987-07-31'),\n  ('J. Beckie', '1994-08-20'),\n  ('S. Labbé', '1986-10-10'),\n  ('K. Sheridan', '1995-07-16'),\n  ('J. Fleming', '1998-03-11'),\n  ('E. McLeod', '1983-02-26'),\n  ('A. Chapman', '1989-01-25'),\n  ('S. Zadorsky', '1992-10-24'),\n  ('Quinn', '1995-08-11'),\n  ('N. Prince', '1995-02-19'),\n  ('V. Gilles', '1996-11-03'),\n  ('A. Leon', '1992-10-02'),\n  ('J. Huitema', '2001-05-08'),\n  ('É. Viens', '1997-02-06'),\n  ('L. Agnew', '1995-03-31'),\n  ('D. Rose', '1999-03-03'),\n  ('S. Woeller', '1990-12-31'),\n  ('M. Kelly', '1992-02-19'),\n  ('J. Hellstrom', '1995-04-02')],\n 'es': [('Jenni Hermoso', '1990-05-09'),\n  ('Alexia Putellas', '1994-02-04'),\n  ('Irene Paredes', '1991-07-04'),\n  ('Sandra Paños', '1992-11-04'),\n  ('Mapi León', '1995-06-13'),\n  ('Marta Corredera', '1991-08-08'),\n  ('Amanda Sampedro', '1993-06-26'),\n  ('Patri Guijarro', '1998-05-17'),\n  ('Virginia Torrecilla', '1994-09-04'),\n  ('Vicky Losada', '1991-03-05'),\n  ('Mariona', '1996-03-19'),\n  ('Aitana Bonmatí', '1998-01-18'),\n  ('Leila Ouahabi', '1993-03-22'),\n  ('Ivana Andrés', '1994-07-13'),\n  ('Andrea Pereira', '1993-09-19'),\n  ('Esther González', '1992-12-08'),\n  ('Lucía García', '1998-07-14'),\n  ('Nahikari', '1997-03-10'),\n  ('Ona Batlle', '1999-06-10'),\n  ('Alba Redondo', '1996-08-27'),\n  ('Marta Cardona', '1995-05-26'),\n  ('Misa', '1999-07-22'),\n  ('Laia Aleixandri', '2000-08-25')],\n 'gb-sct': [('K. Little', '1990-06-29'),\n  ('C. Emslie', '1994-03-08'),\n  ('J. Beattie', '1991-05-13'),\n  ('C. Weir', '1995-06-20'),\n  ('E. Cuthbert', '1998-07-19'),\n  ('E. Mitchell', '1992-09-19'),\n  ('L. Evans', '1992-05-21'),\n  ('L. Alexander', '1991-09-23'),\n  ('R. Corsie', '1989-08-17'),\n  ('S. Howard', '1993-09-17'),\n  ('F. Brown', '1995-03-31'),\n  ('K. Smith', '1994-01-06'),\n  ('J. Ross', '1989-09-18'),\n  ('L. Clelland', '1993-01-26'),\n  ('C. Murray', '1990-05-03'),\n  ('J. Love', '1985-12-06'),\n  ('H. Lauder', '1990-06-04'),\n  ('L. Arnot', '1996-03-01'),\n  ('C. Arthur', '1995-01-21'),\n  ('L. Crichton', '1987-08-06'),\n  ('N. Docherty', '1992-08-23'),\n  ('J. Fife', '1995-12-01'),\n  ('S. Lynn', '1985-10-22')],\n 'se': [('N. Fischer', '1984-08-02'),\n  ('C. Seger', '1985-03-19'),\n  ('M. Eriksson', '1993-09-08'),\n  ('K. Asllani', '1989-07-29'),\n  ('S. Blackstenius', '1996-02-05'),\n  ('S. Jakobsson', '1990-04-23'),\n  ('H. Lindahl', '1983-04-29'),\n  ('F. Rolfö', '1993-11-24'),\n  ('H. Glas', '1993-04-16'),\n  ('A. Ilestedt', '1993-01-17'),\n  ('Z. Mušović', '1996-05-26'),\n  ('O. Schough', '1991-03-11'),\n  ('E. Rubensson', '1993-05-11'),\n  ('J. Andersson', '1993-01-02'),\n  ('N. Björn', '1997-05-04'),\n  ('J. Falk', '1993-04-26'),\n  ('A. Anvegård', '1997-05-10'),\n  ('M. Janogy', '1995-11-12'),\n  ('F. Angeldahl', '1997-07-14'),\n  ('L. Hurtig', '1995-09-05'),\n  ('H. Bennison', '2002-10-16'),\n  ('J. Roddar', '1992-02-16'),\n  ('E. Kullberg', '1991-09-25')],\n 'nz': [('A. Erceg', '1989-11-20'),\n  ('A. Riley', '1987-10-30'),\n  ('R. Percival', '1989-12-07'),\n  ('E. Nayler', '1992-04-17'),\n  ('K. Bowen', '1994-04-15'),\n  ('M. Moore', '1996-06-04'),\n  ('A. Longo', '1991-07-01'),\n  ('R. White', '1993-06-06'),\n  ('V. Esson', '1991-03-06'),\n  ('O. Chance', '1993-10-05'),\n  ('A. Green', '1990-08-20'),\n  ('H. Wilkinson', '1992-05-28'),\n  ('C. Bott', '1995-04-22'),\n  ('B. Hassett', '1990-08-04'),\n  ('K. Rood', '1992-09-02'),\n  ('A. Phillips', '1991-05-06'),\n  ('P. Satchell', '1998-04-13'),\n  ('C. Bunge', '1999-09-21'),\n  ('S. Morton', '1998-08-28'),\n  ('N. Stratford', '1989-02-01'),\n  ('S. Skilton', '1994-10-27'),\n  ('M. van der Meer', '2002-03-27'),\n  ('G. Rennie', '2001-07-07')],\n 'mx': [('K. Robles', '1991-02-15'),\n  ('S. Mayor', '1991-09-23'),\n  ('E. Alvarado', '1998-06-09'),\n  ('A. Cervantes', '1994-01-24'),\n  ('M. Sánchez', '1996-02-20'),\n  ('D. Espinosa', '1999-07-13'),\n  ('J. López', '1999-01-30'),\n  ('C. Jaramillo', '1994-03-15'),\n  ('R. Bernal', '1997-08-31'),\n  ('A. González', '2002-01-31'),\n  ('N. Antonio', '1996-04-02'),\n  ('I. González', '1994-08-14'),\n  ('J. Montoya', '2000-07-03'),\n  ('J. Orejel', '1996-11-14'),\n  ('C. Ferral', '1993-02-16'),\n  ('B. Campos', '1994-02-03'),\n  ('D. Evangelista', '1994-11-05'),\n  ('M. Cadena', '1995-02-13'),\n  ('K. Rodríguez', '1999-03-02'),\n  ('A. Rodríguez', '1996-12-31'),\n  ('M. Villeda', '2001-10-25'),\n  ('M. Delgadillo', '1995-12-08'),\n  ('D. García', '1999-11-11')],\n 'br': [('Miri Couto', '1992-02-29'),\n  ('Emanuelly Barni', '1992-02-29'),\n  ('Jully Mutto', '1988-02-29'),\n  ('Palomy Bastos', '1988-02-29'),\n  ('Letinha Lia', '1984-02-29'),\n  ('Isinha Macapá', '1988-02-29'),\n  ('Becky Saudera', '1992-02-29'),\n  ('Julininha Ruiz', '1992-02-29'),\n  ('Karole Pombal', '1992-02-29'),\n  ('Bianca Revelia', '1988-02-29'),\n  ('Becky Redela', '1992-02-29'),\n  ('Melinda Goiás', '1992-02-29'),\n  ('Cecil Sendela', '2000-02-29'),\n  ('Zoe Tocantins', '1984-02-29'),\n  ('Isaby Camila', '1988-02-29'),\n  ('Niccole Cintra', '1992-02-29'),\n  ('Iris Vieirinha', '1988-02-29'),\n  ('Jandinha Kenedy', '1992-02-29'),\n  ('Kla Elisinha', '1984-02-29'),\n  ('Giovanny Bia', '1988-02-29'),\n  ('Magi Bardini', '1992-02-29'),\n  ('Rafaelly Paraná', '1996-02-29'),\n  ('Licinha Bardini', '1988-02-29')],\n 'cn': [('Wu Haiyan', '1993-02-26'),\n  ('Wang Shuang', '1995-01-23'),\n  ('Tang Jiali', '1995-03-16'),\n  ('Peng Shimeng', '1998-05-12'),\n  ('Liu Shanshan', '1992-03-16'),\n  ('Li Ying', '1993-01-07'),\n  ('Ma Jun', '1989-03-06'),\n  ('Wang Shanshan', '1990-01-27'),\n  ('Zhang Xin', '1992-05-23'),\n  ('Lin Yuping', '1992-02-28'),\n  ('Zhai Qingwei', '1996-09-24'),\n  ('Zhang Rui', '1989-01-17'),\n  ('Gu Yasha', '1990-11-28'),\n  ('Li Mengwen', '1995-03-28'),\n  ('Yang Li', '1991-01-31'),\n  ('Han Peng', '1989-12-20'),\n  ('Pang Fengyue', '1989-01-19'),\n  ('Yao Lingwei', '1995-12-05'),\n  ('Yao Wei', '1997-09-01'),\n  ('Li Jiayue', '1990-06-08'),\n  ('Bi Xiaolin', '1989-09-18'),\n  ('Song Duan', '1995-08-02'),\n  ('Luo Guiping', '1993-04-20')],\n 'be': [('T. Wullaert', '1993-03-19'),\n  ('J. Cayman', '1988-10-12'),\n  ('T. De Caigny', '1997-06-09'),\n  ('J. Biesmans', '1994-05-04'),\n  ('L. Deloose', '1993-06-18'),\n  ('D. Philtjens', '1989-02-26'),\n  ('K. Missipo', '1998-02-03'),\n  ('J. Vanhaevermaet', '1992-04-29'),\n  ('L. De Neve', '1994-10-09'),\n  ('M. Minnaert', '1999-05-05'),\n  ('L. Onzia', '1989-05-30'),\n  ('J. Odeurs', '1997-05-30'),\n  ('N. Evrard', '1995-05-26'),\n  ('D. Vanmechelen', '1999-08-30'),\n  ('C. Vande Velde', '1997-06-06'),\n  ('S. Van Belle', '1999-12-22'),\n  ('A. Tysiak', '2000-01-26'),\n  ('C. Tison', '1998-04-21'),\n  ('L. Wajnblum', '1996-01-22'),\n  ('I. Iliano', '1997-03-02'),\n  ('D. Lemey', '1996-10-07'),\n  ('M. Coutereels', '1986-05-21'),\n  ('H. Eurlings', '2003-01-01')],\n 'pt': [('Cláudia Neto', '1988-04-18'),\n  ('Carole Costa', '1990-05-03'),\n  ('Ana Borges', '1990-06-15'),\n  ('Dolores Silva', '1991-08-07'),\n  ('Sílvia Rebelo', '1989-05-20'),\n  ('Jéssica Silva', '1994-12-11'),\n  ('Patrícia Morais', '1992-06-17'),\n  ('Carolina Mendes', '1987-11-27'),\n  ('Tatiana Pinto', '1994-03-28'),\n  ('Diana Silva', '1995-06-04'),\n  ('Andreia Norton', '1996-08-15'),\n  ('Fátima Pinto', '1996-01-16'),\n  ('Joana Marchão', '1996-10-24'),\n  ('Ana Capeta', '1997-12-22'),\n  ('Inês Pereira', '1999-05-26'),\n  ('Telma Encarnação', '2001-10-11'),\n  ('Kika Nazareth', '2002-11-17'),\n  ('Rute Costa', '1994-06-01'),\n  ('Andreia Jacinto', '2002-06-08'),\n  ('Andreia Faria', '2000-04-19'),\n  ('Alícia Correia', '2003-04-29'),\n  ('Catarina Amado', '1999-07-21'),\n  ('Ana Dias', '1997-10-02')]}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ejercicio 3\n",
    "import re\n",
    "\n",
    "def read_data(path:str) -> list:\n",
    "    \"\"\"\n",
    "    Este método tiene como objetivo la lectura del CSV\n",
    "    línea por línea para devolverlo\n",
    "\n",
    "    Arguments:\n",
    "    path (str): destino de donde se encuentra el CSV a leer\n",
    "    \n",
    "    Returns:\n",
    "    data (list): lista de filas, cada fila con valores leídos\n",
    "    del csv.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    # Es necesario el encoding para poder leer el fichero\n",
    "    with open(path, 'r', encoding='utf-8') as file:\n",
    "        # Leo línea por línea\n",
    "        for lane in file:\n",
    "            # Divido los campos de cada línea por el carácter ','\n",
    "            valores = lane.strip().split(',')\n",
    "            data.append(valores)\n",
    "    return data\n",
    "\n",
    "def parse_nation(nation_url:str) -> str:\n",
    "    \"\"\"\n",
    "    Este método tiene como objetivo el parsear una url de \n",
    "    una nación en el código del país.\n",
    "\n",
    "    Arguments:\n",
    "    nation_url (str): valor de la nación sin parsear\n",
    "    \n",
    "    Returns:\n",
    "    Valor en string con el código del país\n",
    "    \"\"\"\n",
    "    # Creo la regex: que busque los caracteres antes del '.png'\n",
    "    regex = r'\\/([a-z\\-]+)\\.png$'\n",
    "    match = re.search(regex, nation_url)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        # Si no machea, devuelvo vacío\n",
    "        return \"\"\n",
    "     \n",
    "def parse_nation_column(nation_col:list) -> list:\n",
    "    \"\"\"\n",
    "    Este método tiene como objetivo el parseo de una columna\n",
    "    invocando al método parse_nation\n",
    "\n",
    "    Arguments:\n",
    "    nation_col (list): lista a parsear\n",
    "    \n",
    "    Returns:\n",
    "    Lista con todos los elementos parseados\n",
    "    \"\"\"\n",
    "    return [parse_nation(nation_url) for nation_url in nation_col]   \n",
    "\n",
    "def get_columns(data:list, short_name_index:int, col_index:int, country_index:int) -> list:\n",
    "    \"\"\"\n",
    "    Este método tiene como objetivo la extracción en una lista\n",
    "    de toda una columna del dataset, excluyendo el primer valor\n",
    "    que coincide con el nombre de esa columna del CSV.\n",
    "\n",
    "    Arguments:\n",
    "    data (list): lista que contiene todas las filas del csv leido\n",
    "    col_index (int): Índice de la columna que se va a extraer\n",
    "    \n",
    "    Returns:\n",
    "    Lista con todos los elementos de una columna\n",
    "    \"\"\"\n",
    "    col = [[],[],[]]\n",
    "    # Recorro la lista de filas evitando la primera fila (tiene nombres de columnas)\n",
    "    for row in data[1:]: \n",
    "        col[0].append(row[short_name_index])\n",
    "        col[1].append(row[col_index])\n",
    "        col[2].append(row[country_index])\n",
    "\n",
    "    # Devuelvo la columna calculada \n",
    "    return col\n",
    "\n",
    "def group_data(columns:list) -> list:\n",
    "    \"\"\"\n",
    "    Este método tiene como objetivo la agrupación de la lista \n",
    "    que contiene las tres columnas de datos, utilizando la última\n",
    "    (país) para separar duplas de pares que pertenezcan a ese \n",
    "    país\n",
    "\n",
    "    Arguments:\n",
    "    columns (list): lista que contiene las 3 columnas del CSV\n",
    "    \n",
    "    Returns:\n",
    "    Lista que contiene pares agrupados por país\n",
    "    \"\"\"\n",
    "    datos_agrupados = {}\n",
    "    for index in range(len(columns[0])):\n",
    "        short_name = columns[0][index]\n",
    "        col = columns[1][index]\n",
    "        country = columns[2][index]\n",
    "        if country in datos_agrupados:\n",
    "            datos_agrupados[country].append((short_name, col))\n",
    "        else:\n",
    "            datos_agrupados[country] = [(short_name, col)]\n",
    "    return datos_agrupados\n",
    "\n",
    "\n",
    "def create_dictionary(path:str, col_name:str) -> list:\n",
    "    \"\"\"\n",
    "    Este método tiene como objetivo la orquestación de todo\n",
    "    lo necesario para crear el diccionario pedido.\n",
    "\n",
    "    Arguments:\n",
    "    path (str): ruta completa al fichero a leer\n",
    "    col_name (str): nombre de la columna a escoger del dataset\n",
    "    \n",
    "    Returns:\n",
    "    Lista que contiene pares agrupados por país\n",
    "    \"\"\"\n",
    "    # Leo el fichero\n",
    "    data = read_data(path)\n",
    "    # Obtengo los índices de donde está cada columna a consultar\n",
    "    col_index = data[0].index(col_name)\n",
    "    short_name_index = data[0].index(\"short_name\")\n",
    "    nation_url_index = data[0].index(\"nation_flag_url\")\n",
    "    # Obtengo las columnas de lo leído en data\n",
    "    columns = get_columns(data,short_name_index,col_index,nation_url_index)\n",
    "    # Transformo la tercera columna, que es la que contiene la url del país\n",
    "    columns[2]= parse_nation_column(columns[2])\n",
    "    # Agrupo los datos por país y lo devuelvo\n",
    "    return group_data(columns)   \n",
    "\n",
    "filename = \"Data/players22.csv\"\n",
    "# Invoco la función y dejo que el resultado salga por pantalla\n",
    "create_dictionary(filename, \"dob\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f98fc276",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T14:46:38.988273Z",
     "start_time": "2024-04-27T14:46:38.985634Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bce9cf7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T14:46:38.998582Z",
     "start_time": "2024-04-27T14:46:38.989231Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code run without problems\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "filename = \"Data/players22.csv\"\n",
    "output_dictionary = create_dictionary(filename, \"goalkeeping_diving\")\n",
    "\n",
    "assert len(output_dictionary[\"fr\"]) == 23, \"Incorrect list of French players\"\n",
    "assert ('J. Groenen', '13') in output_dictionary[\"nl\"] and \\\n",
    "    ('D. van de Donk', '15') in output_dictionary[\"nl\"] and \\\n",
    "    ('S. Spitse', '16') in output_dictionary[\"nl\"], \"Missing Dutch Players\"\n",
    "print(\"Code run without problems\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adc01d77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T14:46:39.003264Z",
     "start_time": "2024-04-27T14:46:39.000518Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f9850bd",
   "metadata": {},
   "source": [
    "# Ejercicio 4: \n",
    "\n",
    "Uno de los objetivos de la PEC será el tratamiento de ficheros. Cómo podéis comprobar. La carpeta `Data` contiene un fichero llamado `books.zip`.\n",
    "\n",
    "Se pide por lo tanto crear dos funciones diferentes que realicen las siguientes operaciones:\n",
    "\n",
    "- 4.1 (0,5 puntos): Escribir una función que se llame 'zip_decompression' que sea reciva dos parámetros de entrada: la ruta y el nombre del fichero zip y en donde está ubicado, y el nombre de la carpeta en donde se quiere descomprimir los archivos\n",
    "- 4.2 (0,5 puntos): Escribir una función que reciva como parámetros la ruta y el nombre de los ficheros extraídos (mobidick y warworlds) y que devuelva el tamaño de esos archivos en megabytes. Recuerda también mostrar por pantalla el resultado obtenido por esa función\n",
    "\n",
    "<span style=\"font-family: Courier New; background-color: #82b74b; color: #000000; padding: 3px; \">SM</span> **(1 punto)**"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobyDick: 1.18 MB\n",
      "WarWorld: 0.35 MB\n"
     ]
    }
   ],
   "source": [
    "# Ejercicio 4\n",
    "\n",
    "import os\n",
    "import zipfile as zf\n",
    "\n",
    "def zip_decompression(input_path:str, output_path:str):\n",
    "    \"\"\"\n",
    "    Crea un fichero para descomprimir los archivos\n",
    "    y realiza la descompresión.\n",
    "    Arguments:\n",
    "    :param input_path: Path con el fichero zip\n",
    "    :param output_path: Path donde descomprimir el contenido\n",
    "    \"\"\"\n",
    "    # Comprueba que no exista el directorio previamente\n",
    "    if not os.path.exists(output_path):\n",
    "        # Crea el directorio para descomprimir\n",
    "        os.makedirs(output_path)\n",
    "    \n",
    "    # Descomprime el contenido en el output_path\n",
    "    with zf.ZipFile(input_path, 'r') as zip_f:\n",
    "        zip_f.extractall(output_path)\n",
    "  \n",
    "def read_sizes(output_path:str, file_name:str) -> float:\n",
    "    \"\"\"\n",
    "    Lee el tamaño de un fichero \n",
    "    :param output_path: directorio donde se encuentra \n",
    "    :param file_name: nombre del archivo\n",
    "    :return: tamaño leído\n",
    "    \"\"\"\n",
    "    file_path = os.path.join(output_path, file_name)\n",
    "    # Con getsize obtengo el tamaño\n",
    "    return os.path.getsize(file_path) / (1024 * 1024)\n",
    "\n",
    "# Invoco el método para descomprimir y los métodos para leer tamaños\n",
    "zip_decompression(\"Data/books.zip\",\"./Data\")\n",
    "md_size = read_sizes(\"Data\",\"mobyDick.txt\")\n",
    "ww_size = read_sizes(\"Data\",\"warworlds.txt\")\n",
    "print(\"MobyDick:\", \"{:.2f} MB\".format(md_size))\n",
    "print(\"WarWorld:\", \"{:.2f} MB\".format(ww_size))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T14:46:39.027291Z",
     "start_time": "2024-04-27T14:46:39.004222Z"
    }
   },
   "id": "04efa975",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0b69a30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T14:46:39.031Z",
     "start_time": "2024-04-27T14:46:39.028245Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2a303b1",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "# Ejercicio 5\n",
    "\n",
    "Desde la llegada de ChatGPT, el procesado de lenguaje natural \"Natural Language Processing\" se ha combertido en una de las áreas más prometedoras de la inteligencia artificial y la ciencia e datos. Parte de las técnicas que se utilizan están más allá del alcance de este curso, pero también son muy importantes algunas de las técnicas que hemos visto en estas primeras unidades de la asignatura.\n",
    "\n",
    "En concreto, en este ejercicio hemos descargado dos libros de la web del proyecto Gutenberg: [Moby Dick, Or, The Whale de Herman Melville](https://www.gutenberg.org/ebooks/2701) y [The War Of The Worlds, de H.G. Wells](https://www.gutenberg.org/ebooks/36), los hemos simplificado ligeramente y los hemos guardado en los archivos `mobyDick.txt` y `warworlds.txt` que ya deberías de tener extraídos como resultado del ejercicio anterior.\n",
    "\n",
    "En este ejercicio os pedimos que creeis una función `process_book` que reciba como entrada la ruta de un archivo de texto (formato .txt) y una expresión regular (patrón) de Python y devuelva una lista con las **frases** del archivo que contengan alguna coincidencia con el patrón.\n",
    "\n",
    "En concreto, os pedimos que encontréis:\n",
    "\n",
    "- Todas las frases del libro \"War of the Worlds\" que contienen la palabra **war** o la palabra **worlds**.\n",
    "- Todas las frases de \"Moby Dick\" que contienen palabras que empiecen por **whal**.\n",
    "\n",
    "**Notas importantes:**\n",
    "\n",
    "1) En ambos casos, será necesario que los patrones no tengan en cuenta mayúsculas y minúsculas. Por tanto, habrá que devolver las frases que contengan \"worlds\" y también las que contengan **Worlds** o **wORLdS**.\n",
    "\n",
    "2) Como parte del ejercicio, deberá separarse el texto en frases. Éste es un tema que puede llegar a ser muy complejo y por tanto en este ejercicio trabajaremos con una simplificación. En concreto, consideraremos que las frases terminarán **siempre** con un punto \".\" o con un símbolo de interrogación \"?\". Adicionalmente, el texto ha sido simplificado para no contener algunos símbolos conflictivos como los puntos suspensivos. Nótese que muchas de las frases están repartidas en más de una línea de texto. Las frases que se devuelven deben incluir, en todo caso, el símbolo de final de frase (punto \".\" o \"?\").\n",
    "\n",
    "3) Utilizad los principios de **programación funcional** que hemos visto en teoría para resolver este ejercicio y **expresiones regulares**.\n",
    "\n",
    "4) En este notebook encontraréis una celda extra con código que puede utilizar para comprobar que la función se ejecuta correctamente con unas entradas concretas. Tened en cuenta que esto es solo una ayuda y que **es vuestra responsabilidad testar el código de manera adecuada.** En concreto, durante la corrección se llamará el código con otros parámetros.\n",
    "\n",
    "\n",
    "<span style=\"font-family: Courier New; background-color: #ffcc5c; color: #000000; padding: 3px; \">EG</span> **(3 puntos)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dbb80f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T14:46:39.092122Z",
     "start_time": "2024-04-27T14:46:39.032949Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['The War of the Worlds, by H G Wells\\n   ‘But who shall dwell in these worlds if they be inhabited? \\n     Are we or they Lords of the World?  And\\n    how are all things made for man?’\\n                    KEPLER (quoted in The Anatomy of Melancholy)\\n\\nContents\\n BOOK ONE. THE COMING OF THE MARTIANS.',\n ' I, THE EVE OF THE WAR.',\n 'THE EVE OF THE WAR.',\n 'No one gave a thought to the older worlds of space as sources\\nof human danger, or thought of them only to dismiss the idea of life\\nupon them as impossible or improbable .',\n 'The Tasmanians, in spite of their human likeness, were entirely\\nswept out of existence in a war of extermination waged by European\\nimmigrants, in the space of fifty years.',\n 'Men like\\nSchiaparelli watched the red planet it is odd, by-the-bye, that for\\ncountless centuries Mars has been the star of war but failed to\\ninterpret the fluctuating appearances of the markings they mapped so\\nwell.',\n 'The fever of war that would presently\\nclog vein and artery, deaden nerve and destroy brain, had still to\\ndevelop.',\n 'Something very\\nlike the war fever that occasionally runs through a civilised community\\nhad got into my blood, and in my heart I was not so very sorry that I\\nhad to return to Maybury that night.',\n 'I recall particularly the illustration of one of the first pamphlets to\\ngive a consecutive account of the war.',\n 'A young\\nMartian, there can now be no dispute, was really born upon earth during\\nthe war, and it was found attached to its parent, partially budded\\noff, just as young lilybulbs bud off, or like the young animals in the\\nfresh-water polyp.',\n 'Surely,\\nif we have learned nothing else, this war has taught us pity pity for\\nthose witless souls that suffer our dominion.',\n '“This isn’t a war,” said the artilleryman.',\n '“It never was a war, any\\nmore than there’s war between man and ants”.',\n 'And scattered about it, some in\\ntheir overturned war machines, some in the now rigid handling-machines,\\nand a dozen of them stark and silent and laid in a row, were the\\nMartians dead! slain by the putrefactive and disease bacteria against\\nwhich their systems were unprepared; slain as the red weed was being\\nslain; slain, after all man’s devices had failed, by the humblest\\nthings that God, in his wisdom, has put upon this earth.',\n 'At any rate, in all the bodies of the Martians that were examined after\\nthe war, no bacteria except those already known as terrestrial species\\nwere found.']"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejercicio 5\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_sentences(book_path:str) -> list:\n",
    "    \"\"\"\n",
    "    Extrae de un fichero .txt todas las frases que acaben en '?' o en '.'.\n",
    "    :param book_path: Path del fichero\n",
    "    :return: lista de strings con cada frase\n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    sentence = \"\"\n",
    "    with open(book_path, 'r', encoding='utf-8') as file:\n",
    "        # Leo línea por línea el fichero\n",
    "        for line in file:\n",
    "            # Limpio la línea de caracteres especiales\n",
    "            cleaned_line = line.replace(\"\\n\", \"\").replace(\"\\r\", \"\")\n",
    "            # Añado la línea a la frase\n",
    "            sentence += line\n",
    "            # Compruebo si lo que tengo construido como frase\n",
    "            # es una frase que acaba en '?' o en '. '.\n",
    "            # He utilizado la web https://regex101.com/ para\n",
    "            # probar la regex en distintas frases\n",
    "            if re.search('[?.]$', cleaned_line) is not None:\n",
    "                # Lo añado a la lista de frases\n",
    "                cleaned_sentence = sentence\n",
    "                # En el test se aprecia que tienen que quedarse\n",
    "                # los \\n del medio del string, pero el del final\n",
    "                # tiene que eliminarse\n",
    "                if sentence[-1] == \"\\n\":\n",
    "                    cleaned_sentence = sentence[:-1]\n",
    "                # Una vez procesada la frase, la añado a la respuesta\n",
    "                sentences.append(cleaned_sentence)\n",
    "                # Y borro la variable auxiliar para la siguiente frase\n",
    "                sentence=\"\"\n",
    "    return sentences\n",
    "\n",
    "def find_sentences(sentences:list, word_regex:str) -> list:\n",
    "    \"\"\"\n",
    "    A partir de una lista de frases y de una regex, devuelve\n",
    "    todas aquellas frases en las que se encuentre lo expresado\n",
    "    en la regex.\n",
    "    :param sentences: lista con las frases\n",
    "    :param word_regex: regex a aplicar\n",
    "    :return:  lista con aquellas frases donde se encuentren los elementos\n",
    "    pedidos en la regex\n",
    "    \"\"\"\n",
    "    matched_sentences = []\n",
    "    for sentence in sentences:\n",
    "        if re.search(word_regex,sentence) or re.search(word_regex,sentence.lower()):\n",
    "            matched_sentences.append(sentence)\n",
    "                \n",
    "    return matched_sentences\n",
    "\n",
    "def process_book(book_path:str, word_regex:str) -> list:\n",
    "    \"\"\"\n",
    "    Realiza el procesamiento completo: abre el fichero del libro,\n",
    "    lee línea por línea extrayendo frases para, finalmente, aplicar\n",
    "    la regex y obtener las frases que cumplan con la regex.\n",
    "    :param book_path: Path del fichero txt\n",
    "    :param word_regex: regex objetivo\n",
    "    :return: lista con las frases que cumplan la regex\n",
    "    \"\"\"\n",
    "    sentences = extract_sentences(book_path)\n",
    "    return find_sentences(sentences,word_regex)\n",
    "\n",
    "pattern = r'\\b(?:war|worlds)\\b'\n",
    "process_book(\"Data/warworlds.txt\",pattern)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "558f1171",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T14:46:39.135031Z",
     "start_time": "2024-04-27T14:46:39.094075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The War of the Worlds, by H G Wells\\n   ‘But who shall dwell in these worlds if they be inhabited? \\n     Are we or they Lords of the World?  And\\n    how are all things made for man?’\\n                    KEPLER (quoted in The Anatomy of Melancholy)\\n\\nContents\\n BOOK ONE. THE COMING OF THE MARTIANS.', ' I, THE EVE OF THE WAR.', 'THE EVE OF THE WAR.', 'No one gave a thought to the older worlds of space as sources\\nof human danger, or thought of them only to dismiss the idea of life\\nupon them as impossible or improbable .', 'The Tasmanians, in spite of their human likeness, were entirely\\nswept out of existence in a war of extermination waged by European\\nimmigrants, in the space of fifty years.', 'Men like\\nSchiaparelli watched the red planet it is odd, by-the-bye, that for\\ncountless centuries Mars has been the star of war but failed to\\ninterpret the fluctuating appearances of the markings they mapped so\\nwell.', 'The fever of war that would presently\\nclog vein and artery, deaden nerve and destroy brain, had still to\\ndevelop.', 'Something very\\nlike the war fever that occasionally runs through a civilised community\\nhad got into my blood, and in my heart I was not so very sorry that I\\nhad to return to Maybury that night.', 'I recall particularly the illustration of one of the first pamphlets to\\ngive a consecutive account of the war.', 'A young\\nMartian, there can now be no dispute, was really born upon earth during\\nthe war, and it was found attached to its parent, partially budded\\noff, just as young lilybulbs bud off, or like the young animals in the\\nfresh-water polyp.', 'Surely,\\nif we have learned nothing else, this war has taught us pity pity for\\nthose witless souls that suffer our dominion.', '“This isn’t a war,” said the artilleryman.', '“It never was a war, any\\nmore than there’s war between man and ants”.', 'And scattered about it, some in\\ntheir overturned war machines, some in the now rigid handling-machines,\\nand a dozen of them stark and silent and laid in a row, were the\\nMartians dead! slain by the putrefactive and disease bacteria against\\nwhich their systems were unprepared; slain as the red weed was being\\nslain; slain, after all man’s devices had failed, by the humblest\\nthings that God, in his wisdom, has put upon this earth.', 'At any rate, in all the bodies of the Martians that were examined after\\nthe war, no bacteria except those already known as terrestrial species\\nwere found.']\n",
      "Code run without problems\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TEST (Private)\n",
    "pattern = r'\\b(?:war|worlds)\\b'\n",
    "\n",
    "ret = process_book(\"./Data/warworlds.txt\", pattern)\n",
    "\n",
    "print(ret)\n",
    "\n",
    "assert(len(ret) == 15), \"Incorrect Number Of Sentences\"\n",
    "assert(\" I, THE EVE OF THE WAR.\" in ret), \"Missing A sentence \"\n",
    "assert(\"No one gave a thought to the older worlds of space as \\\n",
    "sources\\nof human danger, or thought of them only to dismiss \\\n",
    "the idea of life\\nupon them as impossible or improbable \\\n",
    ".\" in ret), \"Missing A sentence \"\n",
    "\n",
    "\n",
    "print(\"Code run without problems\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T14:46:39.139148Z",
     "start_time": "2024-04-27T14:46:39.135987Z"
    }
   },
   "id": "ae752973eab01d5",
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "nbTranslate": {
   "displayLangs": [
    "ja",
    "en",
    "es"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "ca",
   "targetLang": "es",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
